<h1 align="center"> On-Device AI: ON THE AIr </h1>

<div align="center">
<a href="https://pseudo-lab.com"><img src="https://img.shields.io/badge/PseudoLab-S10-3776AB" alt="PseudoLab"/></a>
<a href="https://discord.gg/EPurkHVtp2"><img src="https://img.shields.io/badge/Discord-BF40BF" alt="Discord Community"/></a>
<a href="https://github.com/Pseudo-Lab/On-Device-AI_On-The-AIr/stargazers"><img src="https://img.shields.io/github/stars/Pseudo-Lab/On-Device-AI_On-The-AIr" alt="Stars Badge"/></a>
<a href="https://github.com/Pseudo-Lab/On-Device-AI_On-The-AIr/network/members"><img src="https://img.shields.io/github/forks/Pseudo-Lab/On-Device-AI_On-The-AIr" alt="Forks Badge"/></a>
<a href="https://github.com/Pseudo-Lab/On-Device-AI_On-The-AIr/pulls"><img src="https://img.shields.io/github/issues-pr/Pseudo-Lab/On-Device-AI_On-The-AIr" alt="Pull Requests Badge"/></a>
<a href="https://github.com/Pseudo-Lab/On-Device-AI_On-The-AIr/issues"><img src="https://img.shields.io/github/issues/Pseudo-Lab/On-Device-AI_On-The-AIr" alt="Issues Badge"/></a>
<a href="https://github.com/Pseudo-Lab/On-Device-AI_On-The-AIr/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/Pseudo-Lab/On-Device-AI_On-The-AIr?color=2b9348"></a>
<a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fpseudo-lab%2FOn-Device-AI_On-The-AIr&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>
</div>
<br>

<!-- sheilds: https://shields.io/ -->
<!-- hits badge: https://hits.seeyoufarm.com/ -->
<h1 align="center"> <img src="./images/logo_v1.jpeg" /> </h1>

> Welcome to **On-Device AI: ON THE AIr** repository! We aim to research On-Device AI with an emphasis on common model compression techniques, conducting paper reviews, and benchmarking real-world performance using NVIDIA Jetson devices. Join us in advancing On-Device AI through open collaboration and innovation! ğŸš€

## ğŸŒŸ í”„ë¡œì íŠ¸ ëª©í‘œ (Project Vision)
_"Propose the optimal model compression techniques for NVIDIA Jetson devices by leveraging the knowledge gained from research paper reviews on model compression methods."_  
- Learn various pruning techniques during this season (10th).
- Apply the learned model compression methods to existing models.
- Foster synergy between individual growth and collective intelligence.
- Promote a knowledge-sharing culture based on the open-source spirit.


## ğŸ§‘ ì—­ë™ì ì¸ íŒ€ ì†Œê°œ (Dynamic Team)

| ì—­í•                  | ì´ë¦„ |  ê¸°ìˆ  ìŠ¤íƒ ë°°ì§€                                                          | ì£¼ìš” ê´€ì‹¬ ë¶„ì•¼                             |
|---------------------|-----|-----------------------------------------------------------------------|----------------------------------------|
| **Project Manager** | [ì •í˜„ìš°](https://github.com/official-vvoo)  | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) ![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C) | On-Device AI, CV, Robotics         |
| **Member**          | [ê¹€ë¯¼ì„±](https://github.com/GreenIdealist)  | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) | -                  |
| **Member**          | [êµ¬ìŠ¹ì—°](https://github.com/rrxloyeon)      | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) | -                  |
| **Member**          | ë¬¸ê·œì‹                                      | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) | -                  |
| **Member**          | ë°•ì„ ì˜                                      | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) | -                  |
| **Member**          | ë°•ì˜ˆë¦¬                                      | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) | -                  |
| **Member**          | ì–‘ë¬¸ê¸°                                      | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) | -                  |
| **Member**          | ì´ëª…ì„                                      | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) | -                  |
| **Member**          | ì •ì§„ìš°                                      | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) | -                  |
| **Member**          | ìµœì˜ˆì œ                                      | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) | -                    |
| **Member**          | [ìµœìœ ì§„](https://github.com/yujin37)        | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) | -                  |
| **Member**          | ìµœí•´ì¸                                      | ![Python](https://img.shields.io/badge/Python-Expert-3776AB) | -                  |



## ğŸš€ í”„ë¡œì íŠ¸ ë¡œë“œë§µ (Project Roadmap)
```mermaid
gantt
    title 2025 On-Device AI í”„ë¡œì íŠ¸ ì—¬ì •
    section ì „ì²´ ì»¤ë¦¬í˜ëŸ¼
    Pruning      :a1, 2025-03-03, 119d
    Quantization :a2, after a1, 120d

    section Pruning ì„¸ë¶€ í™œë™
    SPECIFIC OR UNIVERSAL SPEEDUP   :b1, 2025-03-03, 35d
    WHEN TO PRUNE                   :b2, after b1, 84d

    section ì‹¤ìŠµ ì„¸ë¶€ í™œë™ with Jetson
    Object Detection with Pruning   :c1, 2025-04-01, 43d
    LLM with Pruning                :c2, after c1, 42d
    CV with Pruning                 :c3, after c1, 42d
```


<!-- ## ğŸ› ï¸ ìš°ë¦¬ì˜ ê°œë°œ ë¬¸í™” (Our Development Culture)
**ìš°ë¦¬ì˜ ê°œë°œ ë¬¸í™”**  
```python
class CollaborationFramework:
    def __init__(self):
        self.tools = {
            'communication': 'Discord',
            'version_control': 'GitHub Projects',
            'ci/cd': 'GitHub Actions',
            'docs': 'Github Wiki'
        }
    
    def workflow(self):
        return """ì£¼ê°„ ì‚¬ì´í´:
        1ï¸âƒ£ ì›”ìš”ì¼: ìŠ¤í”„ë¦°íŠ¸ í”Œë˜ë‹ (Notion íƒ€ì„ë¼ì¸ ê³µìœ )
        2ï¸âƒ£ ìˆ˜ìš”ì¼: ì½”ë“œ ë¦¬ë·° ì„¸ì…˜ (Live Share)
        3ï¸âƒ£ ê¸ˆìš”ì¼: ë°ëª¨ë°ì´ (ì‹¤ì œ ì ìš© ì‚¬ë¡€ ë°œí‘œ)"""
``` -->


<!-- ## ğŸ“ˆ ì„±ê³¼ ì§€í‘œ (Achievement Metrics)
**2024 ì£¼ìš” KPI**  
| ì§€í‘œ                     | ëª©í‘œì¹˜ | í˜„ì¬ ë‹¬ì„±ë¥  |
|--------------------------|--------|-------------|
| ì»¤ë°‹ ìˆ˜                  | 1,200  | 83%         |
| ì´ìŠˆ í•´ê²°ë¥               | 95%    | 89%         | 
| ê¸°ìˆ  ë¸”ë¡œê·¸ ê²Œì‹œë¬¼       | 24í¸   | 15í¸        |
| ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ë„          | 8íšŒ    | 5íšŒ         | -->


## ğŸ’» ì£¼ì°¨ë³„ í™œë™ (Activity History)
### Paper Review
| ë‚ ì§œ | ë‚´ìš© | ë°œí‘œì | ì§„í–‰ë°©ì‹ | ì°¸ê³ ìë£Œ | ë¹„ê³  |
| -------- | -------- | ---- | --- | --- | --- |
| 2025/03/05 | OT                                                            | ì •í˜„ìš° | ì˜¨ë¼ì¸ | - |    |
| 2025/03/12 | Unstructured Pruning                                          | êµ¬ìŠ¹ì—° | ì˜¨ë¼ì¸ | [J. Frankle and M. Carbin, â€œThe lottery ticket hypothesis: finding sparse, trainable neural networks,â€ in ICLR, 2019.](https://arxiv.org/abs/1803.03635) |    |
| 2025/03/19 | Structured Pruning                                            | ê¹€ë¯¼ì„± | ì˜¤í”„ë¼ì¸ | [X. Ma, G. Fang, and X. Wang, â€œLLM-Pruner: On the structural pruning of large language models,â€ in NeurIPS, vol. 36, 2023, pp.21 702â€“21 720.](https://arxiv.org/abs/2305.11627) |    |
| 2025/03/26 | Magical Week íœ´ì¼ | ë¯¸ì • | - | - |    |
| 2025/04/03 | Semi-structured Pruning                                       | ìµœìœ ì§„ | ì˜¨ë¼ì¸ | [F. Meng, H. Cheng, K. Li, H. Luo, X. Guo, G. Lu, and X. Sun, â€œPruning filter in filter,â€ in NeurIPSW, 2020.](https://arxiv.org/abs/2009.14410) |    |
| 2025/04/09 | Pruning Before Training                                       | ë¬¸ê·œì‹ | ì˜¨ë¼ì¸ | [S. Liu, T. Chen, X. Chen, L. Shen, D. C. Mocanu, Z. Wang, and M. Pechenizkiy, â€œThe unreasonable effectiveness of random pruning: Return of the most naive baseline for sparse training,â€ in ICLR, 2022.](https://openreview.net/forum?id=VBZJ_3tz-t) |    |
| 2025/04/16 | Pruning During Training: Sparsity Regularization based Methods| ë°•ì˜ˆë¦¬ | ì˜¨ë¼ì¸ | [W. Wen, C. Wu, Y. Wang, Y. Chen, and H. Li, â€œLearning structured sparsity in deep neural networks,â€ in NIPS, 2016.](https://arxiv.org/abs/1608.03665) |    |
| 2025/04/23 | Pruning During Training: Dynamic Sparse Training based Methods| êµ¬ìŠ¹ì—° | ì˜¤í”„ë¼ì¸ | [U. Evci, T. Gale, J. Menick, P. S. Castro, and E. Elsen, â€œRigging the lottery: Making all tickets winners,â€ in ICML, 2020.](https://arxiv.org/abs/1911.11134) |    |
| 2025/04/30 | Magical Week íœ´ì¼ | ë¯¸ì • | - | - |    |
| 2025/05/07 | Pruning During Training: Score-based Methods                  | ìµœí•´ì¸ | ì˜¨ë¼ì¸ | [Y. He, P. Liu, Z. Wang, Z. Hu, and Y. Yang, â€œFilter pruning via geometric median for deep convolutional neural networks acceleration,â€ in CVPR, 2019, pp. 4340â€“4349.](https://arxiv.org/abs/1811.00250) |    |
| 2025/05/14 | Pruning During Training: Differentiable Pruning based methods | ì •ì§„ìš° | ì˜¨ë¼ì¸ | [X. Ning, T. Zhao, W. Li, P. Lei, Y. Wang, and H. Yang, â€œDSA: More efficient budgeted pruning via differentiable sparsity allocation,â€ in ECCV, 2020, pp. 592â€“607.](https://arxiv.org/abs/2004.02164) |  Pseudo Con  |
| 2025/05/21 | Pruning After Training: LTH and its Variants                  | ì´ëª…ì„ | ì˜¨ë¼ì¸ | ì„ ì • ì¤‘ |    |
| 2025/05/28 | Pruning After Training: Other score-based Methods             | ê¹€ë¯¼ì„± | ì˜¤í”„ë¼ì¸ | ì„ ì • ì¤‘ |    |
| 2025/06/04 | Pruning After Training: Sparsity Regularization based Methods | ìµœì˜ˆì œ | ì˜¨ë¼ì¸ | ì„ ì • ì¤‘ |    |
| 2025/06/11 | Pruning After Training: Pruning in Early Training             | ì–‘ë¬¸ê¸° | ì˜¨ë¼ì¸ | ì„ ì • ì¤‘ |    |
| 2025/06/18 | Pruning After Training: Post-Training Pruning                 | ë°•ì„ ì˜ | ì˜¨ë¼ì¸ | ì„ ì • ì¤‘ |    |
| 2025/06/25 | Run-time Pruning                                              | ì •í˜„ìš° | ì˜¤í”„ë¼ì¸ | ì„ ì • ì¤‘ |    |

### Hands-On Pruning with Jetson
| ë‚ ì§œ | ë‚´ìš© | ì§„í–‰ë°©ì‹ | ë¹„ê³  |
| -------- | --- | --- | --- |
| 2025/04/01 | OT ë° ê³„íš ìˆ˜ë¦½                                                  | ì˜¨ë¼ì¸ |    |
| 2025/04/15 | Unstructured Pruning êµ¬í˜„ ë° í•™ìŠµ                                | ì˜¨ë¼ì¸ | Phase1 |
| 2025/04/29 | Structured Pruning êµ¬í˜„ ë° í•™ìŠµ                                  | ì˜¤í”„ë¼ì¸ | Phase1 & Magical Week |
| 2025/05/13 | Zero-shot Pruning êµ¬í˜„ ë° í•™ìŠµ + LLM/CV ëª¨ë¸ ì„ ì • ë° Pruning ê³„íš    | ì˜¤í”„ë¼ì¸ | Phase1 & Pseudo Con |
| 2025/05/27 | Pruning ê¸°ë²• 1 ì ìš©                                             | ì˜¨ë¼ì¸ | Phase2 |
| 2025/06/10 | Pruning ê¸°ë²• 2 ì ìš©                                             | ì˜¤í”„ë¼ì¸ | Phase2 |
| 2025/06/24 | Pruning ê¸°ë²• 3 ì ìš©                                             | ì˜¨ë¼ì¸ | Phase2 |

## ì§„í–‰ ë°©ì‹
### Paper Review
ë§¤ì£¼ ìŠ¤í„°ë”” ì§„í–‰ ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.  
> 1. ê·¼í™© ì´ì•¼ê¸° (20 ~ 30ë¶„ ì˜ˆìƒ)
> 2. ë°œí‘œìë¥¼ ì œì™¸í•œ **ì°¸ì—¬ì**ë“¤ì´ ì¤€ë¹„í•œ On-Device AI ê´€ë ¨ëœ ì´ìŠˆë“¤ì„ ê³µìœ í•œë‹¤. (20 ~ 40ë¶„ ì˜ˆìƒ)
> 3. **ë°œí‘œì**ëŠ” ì¤€ë¹„í•œ ë…¼ë¬¸ ë¦¬ë·°ë¥¼ ë°œí‘œí•œë‹¤. (30ë¶„ ~ 1ì‹œê°„ ì˜ˆìƒ)

ì´ì— ë”°ë¼ ë‹¤ìŒ ë‚´ìš©ë“¤ì„ ì¤€ë¹„í•˜ì‹œë©´ ë©ë‹ˆë‹¤  
**ê³µí†µì‚¬í•­**
- í•´ë‹¹ ì£¼ì°¨ ë…¼ë¬¸ì„ ì½ëŠ”ë‹¤.  

**ë°œí‘œì**
- í•´ë‹¹ ì£¼ì°¨ ë…¼ë¬¸ì— ëŒ€í•œ ë°œí‘œ ì¤€ë¹„ë¥¼ í•œë‹¤.  

**ì°¸ì—¬ì**
- On-Device AIì™€ ê´€ë ¨ëœ ê¸°ìˆ ë“¤(TensorRT, LiteRT, ONNX ë“±)ì˜ íŠ¸ë Œë“œë‚˜ ì´ìŠˆë¥¼ ì¤€ë¹„í•œë‹¤.

## ğŸ’¡ í•™ìŠµ ìì› (Learning Resources)
> ì„¸ë¶€ ë…¼ë¬¸ë“¤ì€ [ì£¼ì°¨ë³„ í™œë™](#ğŸ’»-ì£¼ì°¨ë³„-í™œë™-activity-history) ë‚´ ì°¸ê³ ìë£Œ ì°¸ê³ 

**ì°¸ê³  ë¬¸í—Œ**  
- [Cheng, Hongrong, Miao Zhang, and Javen Qinfeng Shi. "A survey on deep neural network pruning: Taxonomy, comparison, analysis, and 
recommendations." IEEE Transactions on Pattern Analysis and Machine Intelligence (2024).](https://arxiv.org/pdf/2308.06767)


## ğŸŒ± ì°¸ì—¬ ì•ˆë‚´ (How to Engage)
**ì§„í–‰ ì •ë³´**
- ì‹œê°„: ë§¤ì£¼ ìˆ˜ìš”ì¼ ì˜¤í›„ 8ì‹œ
- ì¥ì†Œ: ì˜¨ë¼ì¸ / ì˜¤í”„ë¼ì¸(ê°•ë‚¨ì—­)

**ì°¸ì—¬ ì¡°ê±´**
- **On-Device AI(ê²½ëŸ‰í™”, ìµœì í™” ë“±)ì— ê´€ì‹¬ ìˆìœ¼ì‹  ë¶„**
- **4ê°œì›” ë™ì•ˆ ê¾¸ì¤€íˆ ì°¸ì—¬í•˜ì‹¤ ìˆ˜ ìˆëŠ” ë¶„**
- ë”¥ëŸ¬ë‹ ê¸°ì´ˆ ì§€ì‹ ë³´ìœ í•˜ì‹  ë¶„
- ë…¼ë¬¸ì„ ì½ê³  ë¦¬ë·°í•˜ì‹¤ ìˆ˜ ìˆëŠ” ë¶„

**íŒ€ì›ìœ¼ë¡œ ì°¸ì—¬í•˜ì‹œë ¤ë©´ ëŸ¬ë„ˆ ëª¨ì§‘ ê¸°ê°„ì— ì‹ ì²­í•´ì£¼ì„¸ìš”.**  
- ë§í¬ (ì¤€ë¹„ì¤‘)  

**ëˆ„êµ¬ë‚˜ ì²­ê°•ì„ í†µí•´ ëª¨ì„ì„ ì°¸ì—¬í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**  
1. íŠ¹ë³„í•œ ì‹ ì²­ ì—†ì´ ì •ê¸° ëª¨ì„ ì‹œê°„ì— ë§ì¶”ì–´ ë””ìŠ¤ì½”ë“œ #Room-GH ì±„ë„ë¡œ ì…ì¥
2. Magical Week ì¤‘ í–‰ì‚¬ì— ì°¸ê°€
3. Pseudo Lab í–‰ì‚¬ì—ì„œ ë§Œë‚˜ê¸°

<!-- ## Acknowledgement ğŸ™

OOO is developed as part of Pseudo-Lab's Open Research Initiative. Special thanks to our contributors and the open source community for their valuable insights and contributions. -->

## About Pseudo Lab ğŸ‘‹ğŸ¼</h2>

[Pseudo-Lab](https://pseudo-lab.com/) is a non-profit organization focused on advancing machine learning and AI technologies. Our core values of Sharing, Motivation, and Collaborative Joy drive us to create impactful open-source projects. With over 5k+ researchers, we are committed to advancing machine learning and AI technologies.

<h2>Contributors ğŸ˜ƒ</h2>
<a href="https://github.com/Pseudo-Lab/On-Device-AI_On-The-AIr/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Pseudo-Lab/On-Device-AI_On-The-AIr" />
</a>
<br><br>

<h2>License ğŸ—</h2>

This project is licensed under the [MIT License](https://opensource.org/licenses/MIT).
